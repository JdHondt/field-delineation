{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert patchlets from `EOPatch`es to `.npz` files\n",
    "\n",
    "The deep learning model is trained loading lazily small `npz` files, to optimise disk IO and RAM loading efficiency when size of training data cannot fit into memory.\n",
    "\n",
    "This script converts and chunks the patchlets present in `EOPatch`es to `.npz` files. In each `.npz` file, a number of `chunk_size` samples is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "import os\n",
    "import boto3\n",
    "import fs\n",
    "from fs_s3fs import S3FS\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import dateutil\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from sentinelhub import CRS, BBox\n",
    "from s2cloudless import S2PixelCloudDetector\n",
    "import fs\n",
    "from fs.osfs import OSFS\n",
    "from eolearn.core import FeatureType, EOPatch, EOTask, EOWorkflow, SaveTask, OverwritePermission, EOExecutor, FeatureTypeSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocess(process_fun: Callable, arguments: List[Any], max_workers: int = 4) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Executes multiprocessing with tqdm.\n",
    "    Parameters\n",
    "    ----------\n",
    "    process_fun: A function that processes a single item.\n",
    "    arguments: Arguments with which te function is called.\n",
    "    max_workers: Max workers for the process pool executor.\n",
    "\n",
    "    Returns A list of results.\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(tqdm(executor.map(process_fun, arguments), total=len(arguments)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define filesystem and eopatches location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesystem = S3FS(\"bucket-name\", \n",
    "              aws_access_key_id=\"\",\n",
    "              aws_secret_access_key=\"\",\n",
    "              region=\"eu-central-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCHLETS_FOLDER = 'data/Lithuania/patchlets/2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCHLET_PATHS = [os.path.join(PATCHLETS_FOLDER, patchlet_name) for patchlet_name in filesystem.listdir(PATCHLETS_FOLDER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_numpy(pp):\n",
    "    try: \n",
    "        eop = EOPatch.load(pp, filesystem=filesystem, lazy_loading=True)\n",
    "        X_data = eop.data['BANDS']\n",
    "        X_boundary = np.repeat(eop.mask_timeless['BOUNDARY'][np.newaxis, ...], len(eop.timestamp), axis=0)\n",
    "        X_extent = np.repeat(eop.mask_timeless['EXTENT'][np.newaxis, ...], len(eop.timestamp), axis=0)\n",
    "        X_distance = np.repeat(eop.mask_timeless['DISTANCE'][np.newaxis, ...], len(eop.timestamp), axis=0)\n",
    "        timestamps = eop.timestamp\n",
    "        eop_names = np.repeat([pp], len(eop.timestamp), axis=0)\n",
    "    except: \n",
    "        print(f\"Could not create for {pp}\")\n",
    "        return None, None, None, None, None, None\n",
    "    return X_data, X_boundary, X_extent, X_distance, timestamps, eop_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = multiprocess(generate_numpy, PATCHLET_PATHS, max_workers=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([x[0] for x in results if x[0] is not None])\n",
    "y_boundary = np.concatenate([x[1] for x in results if x[1] is not None])\n",
    "y_extent = np.concatenate([x[2] for x in results if x[2] is not None])\n",
    "y_distance = np.concatenate([x[3] for x in results if x[3] is not None])\n",
    "timestamps = np.concatenate([x[4] for x in results if x[4] is not None])\n",
    "eop_names = np.concatenate([x[5] for x in results if x[5] is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_info_dfs = [] \n",
    "\n",
    "idx = 0\n",
    "chunksize = 2000 \n",
    "for i in range(0, len(X), chunksize):\n",
    "    filename = f'patchlets_field_delineation_{idx}'\n",
    "    eop_names = [x.sp]\n",
    "    chunk_info = {'chunk': filename, 'eopatch'. }\n",
    "        \n",
    "    np.savez(f'arrays1/{filename}}', \n",
    "                X=X[i:i+chunksize], \n",
    "                y_boundary=y_boundary[i:i+chunksize], \n",
    "                y_extent=y_extent[i:i+chunksize], \n",
    "                y_distance=y_distance[i:i+chunksize], \n",
    "                timestamps=timestamps[i:i+chunksize],\n",
    "                eopatches=eop_names[i:i+chunksize])\n",
    "    idx += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to_s3(src_folder, dest_folder): \n",
    "    for arr in src_filesystem.listdir(src_folder): \n",
    "        if arr.startswith('patchlets'): \n",
    "            fs.copy.copy_file(src_fs=src_filesystem, src_path=os.path.join(src_folder, arr), dst_fs=filesystem, dst_path=os.path.join(dest_folder, arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPZ patchlet info dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [] \n",
    "\n",
    "NPZ_PATCHLET_FOLDER = '' # Location of the NPZ files \n",
    "\n",
    "for filename in filesystem.listdir(NPZ_PATCHLET_FOLDER)[:6]:\n",
    "    if filename.startswith('patchlet'):\n",
    "        npz = np.load(filesystem.openbin(f'{NPZ_PATCHLET_FOLDER}/{filename}'), allow_pickle=True)\n",
    "\n",
    "        dfs.append(pd.DataFrame({'chunk': filename, \n",
    "         'eopatch': [os.path.basename(x).split('_')[0] for x in npz['eopatches']],\n",
    "         'patchlet': [os.path.basename(x) for x in npz['eopatches']],\n",
    "         'chunk_pos': [os.path.basename(x).split('_')[1] for x in npz['eopatches']],\n",
    "         'timestamp': npz['timestamps']}))\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv('data/Lithuania/patchlets_meta/patchlet_eopatch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
