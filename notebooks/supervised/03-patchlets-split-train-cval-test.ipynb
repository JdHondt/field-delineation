{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split patchlets into train/cval/test\n",
    "\n",
    "The notebook:\n",
    "\n",
    " * loads the dataframe with the patchlets descriptions\n",
    " * splits the patchlets into training, validation, and test according to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Callable, List, Any\n",
    "from distutils.dir_util import copy_tree\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fs_s3fs import S3FS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocess(process_fun: Callable, arguments: List[Any], max_workers: int = 4) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Executes multiprocessing with tqdm.\n",
    "    Parameters\n",
    "    ----------\n",
    "    process_fun: A function that processes a single item.\n",
    "    arguments: Arguments with which te function is called.\n",
    "    max_workers: Max workers for the process pool executor.\n",
    "\n",
    "    Returns A list of results.\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(tqdm(executor.map(process_fun, arguments), total=len(arguments)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesystem = S3FS(\"bucket-name\", \n",
    "              aws_access_key_id=\"\",\n",
    "              aws_secret_access_key=\"\",\n",
    "              region=\"eu-central-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_S3_PATH = 'data/Lithuania'\n",
    "METADATA_PATH = os.path.join(BASE_S3_PATH, 'patchlets_meta')\n",
    "NPZ_FOLDER_LOCAL = '/home/ubuntu/training_npz'\n",
    "MODEL_DIR = '/home/ubuntu/model'\n",
    "\n",
    "NPZ_FOLDER_S3 = 'data/Lithuania/patchlets_npz' \n",
    "### Train/Test/Validation folders, data should be copied from here locally due to speed \n",
    "\n",
    "PATCHLETS_META_FOLDER = 'data/Lithuania/patchlets_meta/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('tensorflow').disabled = True\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load patchlets metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.read_csv(filesystem.open(f'{METADATA_PATH}/patchlet_details.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>eopatch</th>\n",
       "      <th>patchlet</th>\n",
       "      <th>chunk_pos</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>norm_perc99_b3</th>\n",
       "      <th>norm_meanstd_mean_b0</th>\n",
       "      <th>norm_meanstd_mean_b1</th>\n",
       "      <th>norm_meanstd_mean_b2</th>\n",
       "      <th>norm_meanstd_mean_b3</th>\n",
       "      <th>norm_meanstd_std_b0</th>\n",
       "      <th>norm_meanstd_std_b1</th>\n",
       "      <th>norm_meanstd_std_b2</th>\n",
       "      <th>norm_meanstd_std_b3</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patchlets_field_delineation_0.npz</td>\n",
       "      <td>eopatch-0036</td>\n",
       "      <td>eopatch-0036_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>442</td>\n",
       "      <td>4108</td>\n",
       "      <td>1218.079838</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>441.325803</td>\n",
       "      <td>...</td>\n",
       "      <td>2922.651155</td>\n",
       "      <td>1212.953566</td>\n",
       "      <td>948.126377</td>\n",
       "      <td>960.306575</td>\n",
       "      <td>1804.907503</td>\n",
       "      <td>468.738789</td>\n",
       "      <td>168.731122</td>\n",
       "      <td>260.523992</td>\n",
       "      <td>498.383968</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patchlets_field_delineation_0.npz</td>\n",
       "      <td>eopatch-0036</td>\n",
       "      <td>eopatch-0036_0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>359</td>\n",
       "      <td>3699</td>\n",
       "      <td>1284.585728</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>519.615472</td>\n",
       "      <td>...</td>\n",
       "      <td>3431.897393</td>\n",
       "      <td>1406.046835</td>\n",
       "      <td>1065.360873</td>\n",
       "      <td>1056.628138</td>\n",
       "      <td>2334.737760</td>\n",
       "      <td>635.300720</td>\n",
       "      <td>178.551102</td>\n",
       "      <td>304.276842</td>\n",
       "      <td>535.619971</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patchlets_field_delineation_0.npz</td>\n",
       "      <td>eopatch-0036</td>\n",
       "      <td>eopatch-0036_0</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>509</td>\n",
       "      <td>3953</td>\n",
       "      <td>1449.912735</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>604.895936</td>\n",
       "      <td>...</td>\n",
       "      <td>3431.897393</td>\n",
       "      <td>1406.046835</td>\n",
       "      <td>1065.360873</td>\n",
       "      <td>1056.628138</td>\n",
       "      <td>2334.737760</td>\n",
       "      <td>635.300720</td>\n",
       "      <td>178.551102</td>\n",
       "      <td>304.276842</td>\n",
       "      <td>535.619971</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patchlets_field_delineation_0.npz</td>\n",
       "      <td>eopatch-0036</td>\n",
       "      <td>eopatch-0036_0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>578</td>\n",
       "      <td>3975</td>\n",
       "      <td>1499.046513</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>619.099661</td>\n",
       "      <td>...</td>\n",
       "      <td>3431.897393</td>\n",
       "      <td>1406.046835</td>\n",
       "      <td>1065.360873</td>\n",
       "      <td>1056.628138</td>\n",
       "      <td>2334.737760</td>\n",
       "      <td>635.300720</td>\n",
       "      <td>178.551102</td>\n",
       "      <td>304.276842</td>\n",
       "      <td>535.619971</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patchlets_field_delineation_0.npz</td>\n",
       "      <td>eopatch-0036</td>\n",
       "      <td>eopatch-0036_0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>610</td>\n",
       "      <td>3707</td>\n",
       "      <td>1409.728043</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>570.944169</td>\n",
       "      <td>...</td>\n",
       "      <td>3431.897393</td>\n",
       "      <td>1406.046835</td>\n",
       "      <td>1065.360873</td>\n",
       "      <td>1056.628138</td>\n",
       "      <td>2334.737760</td>\n",
       "      <td>635.300720</td>\n",
       "      <td>178.551102</td>\n",
       "      <td>304.276842</td>\n",
       "      <td>535.619971</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               chunk       eopatch        patchlet  chunk_pos  \\\n",
       "0  patchlets_field_delineation_0.npz  eopatch-0036  eopatch-0036_0          0   \n",
       "1  patchlets_field_delineation_0.npz  eopatch-0036  eopatch-0036_0          1   \n",
       "2  patchlets_field_delineation_0.npz  eopatch-0036  eopatch-0036_0          2   \n",
       "3  patchlets_field_delineation_0.npz  eopatch-0036  eopatch-0036_0          3   \n",
       "4  patchlets_field_delineation_0.npz  eopatch-0036  eopatch-0036_0          4   \n",
       "\n",
       "    timestamp  minimum  maximum         mean  median         std  ...  \\\n",
       "0  2019-03-22      442     4108  1218.079838  1070.0  441.325803  ...   \n",
       "1  2019-04-01      359     3699  1284.585728  1098.0  519.615472  ...   \n",
       "2  2019-04-18      509     3953  1449.912735  1209.0  604.895936  ...   \n",
       "3  2019-04-23      578     3975  1499.046513  1247.0  619.099661  ...   \n",
       "4  2019-04-26      610     3707  1409.728043  1179.0  570.944169  ...   \n",
       "\n",
       "   norm_perc99_b3  norm_meanstd_mean_b0  norm_meanstd_mean_b1  \\\n",
       "0     2922.651155           1212.953566            948.126377   \n",
       "1     3431.897393           1406.046835           1065.360873   \n",
       "2     3431.897393           1406.046835           1065.360873   \n",
       "3     3431.897393           1406.046835           1065.360873   \n",
       "4     3431.897393           1406.046835           1065.360873   \n",
       "\n",
       "   norm_meanstd_mean_b2  norm_meanstd_mean_b3  norm_meanstd_std_b0  \\\n",
       "0            960.306575           1804.907503           468.738789   \n",
       "1           1056.628138           2334.737760           635.300720   \n",
       "2           1056.628138           2334.737760           635.300720   \n",
       "3           1056.628138           2334.737760           635.300720   \n",
       "4           1056.628138           2334.737760           635.300720   \n",
       "\n",
       "   norm_meanstd_std_b1  norm_meanstd_std_b2  norm_meanstd_std_b3  validation  \n",
       "0           168.731122           260.523992           498.383968       False  \n",
       "1           178.551102           304.276842           535.619971       False  \n",
       "2           178.551102           304.276842           535.619971       False  \n",
       "3           178.551102           304.276842           535.619971       False  \n",
       "4           178.551102           304.276842           535.619971       False  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5027.000000\n",
       "mean       17.090511\n",
       "std         3.661889\n",
       "min         3.000000\n",
       "25%        15.000000\n",
       "50%        18.000000\n",
       "75%        20.000000\n",
       "max        27.000000\n",
       "Name: patchlet, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.groupby('patchlet')['patchlet'].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146.86153846153846"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gdf)/len(gdf.eopatch.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train/validation/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = gdf[~gdf.validation]\n",
    "TEST_DATASET = gdf[gdf.validation]\n",
    "\n",
    "eops = TRAIN_DATASET.eopatch.unique()\n",
    "validation_eops = np.random.choice(eops, int(len(eops)*0.1))\n",
    "\n",
    "VALIDATION_DATASET = TRAIN_DATASET[TRAIN_DATASET.eopatch.isin(validation_eops)]\n",
    "TRAIN_DATASET = TRAIN_DATASET[~TRAIN_DATASET.eopatch.isin(validation_eops)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TRAIN/TEST/VALIDATION/FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bucket should be mounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATASET.to_csv('/home/ubuntu/{PATCHLETS_META_FOLDER}/patchlet_details_train_dataset.csv', index=False)\n",
    "# VALIDATION_DATASET.to_csv('/home/ubuntu/{PATCHLETS_META_FOLDER}/patchlet_details_validation_dataset.csv', index=False)\n",
    "# TEST_DATASET.to_csv('/home/ubuntu/{PATCHLETS_META_FOLDER}/patchlet_details_test_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = pd.read_csv(filesystem.open(f'{PATCHLETS_META_FOLDER}/patchlet_details_train_dataset.csv'))\n",
    "VALIDATION_DATASET = pd.read_csv(filesystem.open(f'{PATCHLETS_META_FOLDER}/patchlet_details_validation_dataset.csv'))\n",
    "TEST_DATASET = pd.read_csv(filesystem.open(f'{PATCHLETS_META_FOLDER}/patchlet_details_test_dataset.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_val_split(chunk):\n",
    "    if chunk.startswith('patchlets'):\n",
    "        print(f\"Processing chunk: {chunk}\")\n",
    "        data = np.load(os.path.join(NPZ_FOLDER_LOCAL, chunk), allow_pickle=True)\n",
    "\n",
    "        idxs_train = TRAIN_DATASET[TRAIN_DATASET.chunk == chunk].chunk_pos \n",
    "        idxs_test = TEST_DATASET[TEST_DATASET .chunk == chunk].chunk_pos \n",
    "        idxs_val = VALIDATION_DATASET[VALIDATION_DATASET.chunk == chunk].chunk_pos  \n",
    "\n",
    "        train = {}\n",
    "        for key in data.keys():\n",
    "            train[key] = data[key][idxs_train]\n",
    "\n",
    "\n",
    "        test = {}\n",
    "        for key in data.keys():\n",
    "            test[key] = data[key][idxs_test]\n",
    "\n",
    "        val = {}\n",
    "        for key in data.keys():\n",
    "            val[key] = data[key][idxs_val]\n",
    "\n",
    "\n",
    "\n",
    "        np.savez(os.path.join(NPZ_FOLDER_LOCAL, 'train', chunk), **train)\n",
    "        np.savez(os.path.join(NPZ_FOLDER_LOCAL, 'test', chunk), **test)\n",
    "        np.savez(os.path.join(NPZ_FOLDER_LOCAL, 'validation', chunk), **val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test/train/validation NPZ files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocess(test_train_val_split, os.listdir(NPZ_FOLDER_LOCAL), max_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check results with some sanity checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.path.join(NPZ_FOLDER_LOCAL, 'train')\n",
    "val_folder = os.path.join(NPZ_FOLDER_LOCAL, 'validation')\n",
    "test_folder = os.path.join(NPZ_FOLDER_LOCAL, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For chunk patchlets_field_delineation_1.npz the dataframe and npz files lengths match.\n",
      "For chunk patchlets_field_delineation_35.npz the dataframe and npz files lengths match.\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 35]: \n",
    "    chunk = f'patchlets_field_delineation_{i}.npz'\n",
    "\n",
    "    train_chunk = np.load(os.path.join(train_folder, chunk))\n",
    "    test_chunk = np.load(os.path.join(test_folder, chunk))\n",
    "    val_chunk = np.load(os.path.join(val_folder, chunk))\n",
    "\n",
    "    assert len(TRAIN_DATASET[TRAIN_DATASET.chunk == chunk].chunk_pos) == train_chunk['y_boundary'].shape[0]\n",
    "    assert len(VALIDATION_DATASET[VALIDATION_DATASET.chunk == chunk].chunk_pos) == val_chunk['y_boundary'].shape[0]\n",
    "    assert len(TEST_DATASET[TEST_DATASET.chunk == chunk].chunk_pos) == test_chunk['y_boundary'].shape[0]\n",
    "\n",
    "    assert len(TRAIN_DATASET[TRAIN_DATASET.chunk == chunk].chunk_pos) == train_chunk['y_extent'].shape[0]\n",
    "    assert len(VALIDATION_DATASET[VALIDATION_DATASET.chunk == chunk].chunk_pos) == val_chunk['y_extent'].shape[0]\n",
    "    assert len(TEST_DATASET[TEST_DATASET.chunk == chunk].chunk_pos) == test_chunk['y_extent'].shape[0]\n",
    "\n",
    "    assert len(TRAIN_DATASET[TRAIN_DATASET.chunk == chunk].chunk_pos) == train_chunk['y_distance'].shape[0]\n",
    "    assert len(VALIDATION_DATASET[VALIDATION_DATASET.chunk == chunk].chunk_pos) == val_chunk['y_distance'].shape[0]\n",
    "    assert len(TEST_DATASET[TEST_DATASET.chunk == chunk].chunk_pos) == test_chunk['y_distance'].shape[0]\n",
    "    \n",
    "    assert len(TRAIN_DATASET[TRAIN_DATASET.chunk == chunk].chunk_pos) == train_chunk['X'].shape[0]\n",
    "    assert len(VALIDATION_DATASET[VALIDATION_DATASET.chunk == chunk].chunk_pos) == val_chunk['X'].shape[0]\n",
    "    assert len(TEST_DATASET[TEST_DATASET.chunk == chunk].chunk_pos) == test_chunk['X'].shape[0]\n",
    "    \n",
    "    print(f\"For chunk {chunk} the dataframe and npz files lengths match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
